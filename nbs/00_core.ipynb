{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> interect computer by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_model(MODEL_PATH=None): \n",
    "    \"\"\" 加载模型 \"\"\"\n",
    "    import torch\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n",
    "\n",
    "    if MODEL_PATH == None:\n",
    "        MODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n",
    "    \n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "    config.gradient_checkpointing = True\n",
    "    config.do_sample = True\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        device_map = \"auto\",\n",
    "        trust_remote_code = True,\n",
    "        quantization_config=quantization_config,\n",
    "        config=config\n",
    "    )\n",
    "    print(model)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def resp_from_model(instruction,model=None):\n",
    "    \"\"\" 获取模型回复\"\"\"\n",
    "    if model==None:\n",
    "        print('没有正常获取到模型！')\n",
    "        return \n",
    "    import textwrap\n",
    "    import transformers\n",
    "    \n",
    "    \n",
    "    def make_inference(instruction):\n",
    "        instruction_format = \"[INST]{instruction}[/INST]\"\n",
    "        text = instruction_format.format(instruction=instruction)\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
    "    \n",
    "        outputs = model.generate(**inputs, max_new_tokens=2000)\n",
    "        output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return output_text\n",
    "\n",
    "    return make_inference(instruction)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "Write Python code to solve this problem in a brute force manner. You will only print the final result.\n",
    "\n",
    "Find the largest two digit prime number which is also a prime number when the digits are reversed.\n",
    "\n",
    "Reminder: You will write Python code. You do not care about the efficiency of the solution, you will only care about the correctness.\n",
    "\"\"\".strip()\n",
    "output_text = resp_from_model(instruction)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def code_extract(reply):\n",
    "    import re\n",
    "    def extract_code(reply):\n",
    "        pattern = r\"```python([\\s\\S]*?)```\"\n",
    "        matches = re.findall(pattern, reply)\n",
    "        code = \"\\n\\n\".join(matches)\n",
    "        if code:\n",
    "            return code\n",
    "        pattern = r\"```([\\s\\S]*?)```\"\n",
    "        matches = re.findall(pattern, reply)\n",
    "        code = \"\\n\\n\".join(matches)\n",
    "        return code\n",
    "    return extract_code(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_extract('[INST]Write Python code to solve this problem in a brute force manner. You will only print the final result.\\n\\nFind the largest two digit prime number which is also a prime number when the digits are reversed.\\n\\nReminder: You will write Python code. You do not care about the efficiency of the solution, you will only care about the correctness.[/INST] Here is a brute force solution to find the largest two digit prime number which is also a prime number when the digits are reversed:\\n\\n```python\\ndef is\\\\_prime(n):\\nfor i in range(2, int(n**0.5) + 1):\\nif n % i == 0:\\nreturn False\\nreturn True\\n\\nlargest\\\\_prime = -1\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def code_exec(code, time_limit_seconds=20):\n",
    "    import sys\n",
    "    import io\n",
    "    import contextlib\n",
    "    import signal\n",
    "    \n",
    "    def run_python_code(code, time_limit_seconds=20):\n",
    "        @contextlib.contextmanager\n",
    "        def time_limit(seconds):\n",
    "            def signal_handler(signum, frame):\n",
    "                raise TimeoutError(\"Timed out!\")\n",
    "            signal.signal(signal.SIGALRM, signal_handler)\n",
    "            signal.alarm(seconds)\n",
    "            try:\n",
    "                yield\n",
    "            finally:\n",
    "                signal.alarm(0)\n",
    "    \n",
    "        old_stdout = sys.stdout\n",
    "        redirected_output = sys.stdout = io.StringIO()\n",
    "    \n",
    "        try:\n",
    "            with time_limit(time_limit_seconds):\n",
    "                exec(code)\n",
    "        except TimeoutError as e:\n",
    "            print(\"Code execution timed out\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "    \n",
    "        return redirected_output.getvalue()\n",
    "    return run_python_code(code, time_limit_seconds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: module 'signal' has no attribute 'SIGALRM'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execution_output = code_exec(\"\"\"\n",
    "print(1+3)\n",
    "\"\"\", time_limit_seconds=5)\n",
    "\n",
    "print(execution_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def solve_list_by_py(df_ori,problem = 'problem'):\n",
    "    df = df_ori\n",
    "    from collections import defaultdict\n",
    "\n",
    "    instruction_template = \"\"\"\n",
    "    Write Python code to solve this problem in a brute force manner. You will only print the final result.\n",
    "    \n",
    "    {problem}\n",
    "    \n",
    "    Reminder:\n",
    "    - You will write Python code.\n",
    "    - You will only attempt to solve the problem with brute force.\n",
    "    - You will only print the final result.\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    answers = []\n",
    "    \n",
    "    for problem in df[problem]:\n",
    "        print(problem)\n",
    "        responses = defaultdict(int)\n",
    "        \n",
    "        for _ in range(3):\n",
    "            instruction = instruction_template.format(problem=problem)\n",
    "            output_text = make_inference(instruction)\n",
    "            print(f\"{output_text=}\")\n",
    "            code = extract_code(output_text)\n",
    "            print(f\"{code=}\")\n",
    "            execution_output = run_python_code(code)\n",
    "            print(f\"{execution_output=}\")\n",
    "            try:\n",
    "                result = int(execution_output)\n",
    "                responses[result] += 1\n",
    "            except ValueError:\n",
    "                continue\n",
    "            \n",
    "        if len(responses) == 0:\n",
    "            answer = 1\n",
    "            answers.append(answer)  # random guess\n",
    "        else:\n",
    "            answer = sorted([(v,k) for k,v in responses.items()])[-1][-1]\n",
    "            answers.append(answer%1000)  # most common guess\n",
    "    \n",
    "    df[\"answer\"] = answers\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; \n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
