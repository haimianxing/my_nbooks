{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":67121,"databundleVersionId":7806901,"sourceType":"competition"},{"sourceId":6572938,"sourceType":"datasetVersion","datasetId":3600418},{"sourceId":7930545,"sourceType":"datasetVersion","datasetId":4661387},{"sourceId":164964691,"sourceType":"kernelVersion"},{"sourceId":10716,"sourceType":"modelInstanceVersion","modelInstanceId":8658}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Phi2 SFT training baseline\n\n## data\n\nuse all public data, but I dropped the dupilcate rewrite prompts.\n\n## hyperparamters\n\nepoch: 5\n\nbatch size: 2\n\ngradient_accumulation_steps: 8\n\nmax_seq_length: 1024\n\nlearing rate: 1e-4\n\n\ninference notebook click [here](https://www.kaggle.com/code/mozhiwenmzw/0-61-llmpr-phi2-sft-model-generate-infer?scriptVersionId=169380324)","metadata":{}},{"cell_type":"code","source":"!pip install -Uq /kaggle/input/llm-whls/bitsandbytes-0.41.1-py3-none-any.whl\n!pip install -Uq /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n!pip install -Uq /kaggle/input/library-off-for-llm/transformers-4.38.2-py3-none-any.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-30T14:54:55.105603Z","iopub.execute_input":"2024-05-30T14:54:55.105953Z","iopub.status.idle":"2024-05-30T14:55:38.216673Z","shell.execute_reply.started":"2024-05-30T14:54:55.105925Z","shell.execute_reply":"2024-05-30T14:55:38.215584Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -Uq /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:55:38.218786Z","iopub.execute_input":"2024-05-30T14:55:38.219085Z","iopub.status.idle":"2024-05-30T14:55:50.889719Z","shell.execute_reply.started":"2024-05-30T14:55:38.219058Z","shell.execute_reply":"2024-05-30T14:55:50.888459Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom transformers import TrainingArguments\n\nfrom trl import SFTTrainer, DataCollatorForCompletionOnlyLM\nfrom peft import LoraConfig","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:55:50.891177Z","iopub.execute_input":"2024-05-30T14:55:50.891491Z","iopub.status.idle":"2024-05-30T14:56:10.479386Z","shell.execute_reply.started":"2024-05-30T14:55:50.891463Z","shell.execute_reply":"2024-05-30T14:56:10.478585Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-30 14:56:02.677464: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-30 14:56:02.677562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-30 14:56:02.804752: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"exp_name = 'phi2_public_data_sft'\ndata_path = '/kaggle/input/llmpr-public-10k-unique/public_10k_unique_rewrite_prompt.csv'\nmodel_path = '/kaggle/input/phi/transformers/2/1'\noutput_path = f'outputs'\nmodel_save_path =  f'{exp_name}_adapter'","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:56:10.481856Z","iopub.execute_input":"2024-05-30T14:56:10.482991Z","iopub.status.idle":"2024-05-30T14:56:10.487159Z","shell.execute_reply.started":"2024-05-30T14:56:10.482955Z","shell.execute_reply":"2024-05-30T14:56:10.486185Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"epochs=5\nbatch_size=1 # 2 \nmax_seq_length=512 # 1024 \nlr = 1e-4","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:56:10.488517Z","iopub.execute_input":"2024-05-30T14:56:10.488872Z","iopub.status.idle":"2024-05-30T14:56:10.508293Z","shell.execute_reply.started":"2024-05-30T14:56:10.488838Z","shell.execute_reply":"2024-05-30T14:56:10.507496Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(data_path)\ntrain_df, val_df = train_test_split(df, test_size=0.3, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:56:10.509296Z","iopub.execute_input":"2024-05-30T14:56:10.509585Z","iopub.status.idle":"2024-05-30T14:56:11.107830Z","shell.execute_reply.started":"2024-05-30T14:56:10.509561Z","shell.execute_reply":"2024-05-30T14:56:11.106841Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:56:11.109051Z","iopub.execute_input":"2024-05-30T14:56:11.109359Z","iopub.status.idle":"2024-05-30T14:56:11.199730Z","shell.execute_reply.started":"2024-05-30T14:56:11.109334Z","shell.execute_reply":"2024-05-30T14:56:11.198673Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    model_path,\n    )\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:56:11.200888Z","iopub.execute_input":"2024-05-30T14:56:11.201161Z","iopub.status.idle":"2024-05-30T14:56:11.319918Z","shell.execute_reply.started":"2024-05-30T14:56:11.201136Z","shell.execute_reply":"2024-05-30T14:56:11.319095Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype='float16',\n        bnb_4bit_use_double_quant=False,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:56:11.321263Z","iopub.execute_input":"2024-05-30T14:56:11.322059Z","iopub.status.idle":"2024-05-30T14:56:11.327989Z","shell.execute_reply.started":"2024-05-30T14:56:11.322020Z","shell.execute_reply":"2024-05-30T14:56:11.327156Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_path,\n                                             quantization_config=bnb_config,\n                                             trust_remote_code=True,\n                                             use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:56:11.331851Z","iopub.execute_input":"2024-05-30T14:56:11.332126Z","iopub.status.idle":"2024-05-30T14:57:12.020062Z","shell.execute_reply.started":"2024-05-30T14:56:11.332101Z","shell.execute_reply":"2024-05-30T14:57:12.019129Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f97f5ab9e404721bcbfc21e07f2846c"}},"metadata":{}},{"name":"stderr","text":"You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.gradient_checkpointing = False","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:57:12.021290Z","iopub.execute_input":"2024-05-30T14:57:12.021636Z","iopub.status.idle":"2024-05-30T14:57:12.026418Z","shell.execute_reply.started":"2024-05-30T14:57:12.021601Z","shell.execute_reply":"2024-05-30T14:57:12.025429Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def token_len(text):\n    tokenized = tokenizer(text, return_length=True)\n    length = tokenized['length'][0]\n    return length","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:57:12.027762Z","iopub.execute_input":"2024-05-30T14:57:12.028591Z","iopub.status.idle":"2024-05-30T14:57:12.038153Z","shell.execute_reply.started":"2024-05-30T14:57:12.028555Z","shell.execute_reply":"2024-05-30T14:57:12.037255Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['rewritten_text'])):\n        ori_text = example['original_text'][i]\n        rew_text = example['rewritten_text'][i]\n        rew_prompt = example['rewrite_prompt'][i]\n        text = f\"Instruct: Original Text:{ori_text}\\nRewritten Text:{rew_text}\\nWrite a prompt that was likely given to the LLM to rewrite original text into rewritten text.Output: {rew_prompt}\"\n        if token_len(text) > max_seq_length:\n            continue\n        output_texts.append(text)\n    return output_texts","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:57:12.039112Z","iopub.execute_input":"2024-05-30T14:57:12.039393Z","iopub.status.idle":"2024-05-30T14:57:12.048123Z","shell.execute_reply.started":"2024-05-30T14:57:12.039359Z","shell.execute_reply":"2024-05-30T14:57:12.047348Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"response_template = \"Output:\"\ncollator = DataCollatorForCompletionOnlyLM(response_template=response_template, \n                                           tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:57:12.049188Z","iopub.execute_input":"2024-05-30T14:57:12.049616Z","iopub.status.idle":"2024-05-30T14:57:12.065009Z","shell.execute_reply.started":"2024-05-30T14:57:12.049581Z","shell.execute_reply":"2024-05-30T14:57:12.064169Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"dense\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:57:12.066078Z","iopub.execute_input":"2024-05-30T14:57:12.066356Z","iopub.status.idle":"2024-05-30T14:57:12.071465Z","shell.execute_reply.started":"2024-05-30T14:57:12.066334Z","shell.execute_reply":"2024-05-30T14:57:12.070618Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir = output_path,\n    fp16=True,\n    learning_rate=lr,\n    optim=\"adafactor\",\n    num_train_epochs=epochs,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size*2,\n    gradient_accumulation_steps=8,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    logging_steps=50,\n    lr_scheduler_type=\"cosine\",\n    warmup_ratio=0.1,\n    weight_decay=0.01,\n    report_to='none',\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:57:12.072669Z","iopub.execute_input":"2024-05-30T14:57:12.073474Z","iopub.status.idle":"2024-05-30T14:57:12.081027Z","shell.execute_reply.started":"2024-05-30T14:57:12.073449Z","shell.execute_reply":"2024-05-30T14:57:12.080221Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    args = args,\n    max_seq_length=max_seq_length,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    formatting_func=formatting_prompts_func,\n    data_collator=collator,\n    peft_config=peft_config,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:57:12.082041Z","iopub.execute_input":"2024-05-30T14:57:12.082296Z","iopub.status.idle":"2024-05-30T14:57:50.599917Z","shell.execute_reply.started":"2024-05-30T14:57:12.082273Z","shell.execute_reply":"2024-05-30T14:57:50.598961Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e4ffcbd30c74af5b10e4e28014a458c"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d85bb8dd5c4a519bdcbf22f8f7a2ad"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:57:50.601372Z","iopub.execute_input":"2024-05-30T14:57:50.601753Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9' max='2640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   9/2640 01:16 < 7:57:15, 0.09 it/s, Epoch 0.02/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(model_save_path)\ntokenizer.save_pretrained(model_save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}