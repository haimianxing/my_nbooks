{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60893,"databundleVersionId":7000181,"sourceType":"competition"},{"sourceId":6724823,"sourceType":"datasetVersion","datasetId":3873965}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 2px; color:#9E3F00; font-size:180%; text-align:left;padding: 0px; border-bottom: 3px solid #9E3F00\">AutoGluon released the v1.0.0 Nov 30, 2023 ! Check the site below for what’s new in the version. https://auto.gluon.ai/stable/index.html</p>","metadata":{"_uuid":"7bed8d82-6063-4301-867a-134cdb142bf0","_cell_guid":"15fab63c-021a-4f32-9726-a89fca4701f5","trusted":true}},{"cell_type":"markdown","source":"### In this notebook we are using the latest pre-release 1.0.1b20240101 and I will try to show you some advanced examples what you can do in the framework.","metadata":{"_uuid":"0668affa-a39d-4cec-b746-248089d0b292","_cell_guid":"5afc1909-311a-4ef6-8171-50b20b191bcb","trusted":true}},{"cell_type":"code","source":"!pip install autogluon==1.0.1b20240101 -q","metadata":{"_uuid":"3243e2b2-928f-4aa0-aff2-fc4ee9f6345b","_cell_guid":"b767b519-c0ac-4666-8f17-34d399128114","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:50:25.524311Z","iopub.execute_input":"2024-02-02T10:50:25.524767Z","iopub.status.idle":"2024-02-02T10:55:46.634063Z","shell.execute_reply.started":"2024-02-02T10:50:25.52472Z","shell.execute_reply":"2024-02-02T10:55:46.631799Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can also install the TabPFN library for later use if running on GPU.","metadata":{"_uuid":"a8117257-12e8-4e67-aa98-b5af9cf05aba","_cell_guid":"a8dcf823-2aba-4de4-bbc5-ab5af9c8f602","trusted":true}},{"cell_type":"code","source":"#!pip install autogluon.tabular[tabpfn]==1.0.1b20231208 -q","metadata":{"_uuid":"e7ae2c57-234d-4f3e-9b3a-31b8b0b2fd52","_cell_guid":"7b70f857-4b82-4df3-bd5c-cea2c5d2abf0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We are doing the label encoding before the AG feature engineering part. Can also be done inside the AG engine. But for the later distillation it worked better this way here. Some extra features are added based on the Age column. Feature Engineering is equal as important as model engineering, but we leave it with only the FE below.","metadata":{"_uuid":"b5996241-0954-467c-9eac-9458df5c75d5","_cell_guid":"7b155c4c-3a16-4953-a1fc-74177130a8f7","trusted":true}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nfrom autogluon.tabular import TabularPredictor\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\n\ntrain_df = pd.read_csv('/kaggle/input/playground-series-s3e26/train.csv')\n\n# Advanced feature engineering for training data\ntrain_df['Age_Group'] = pd.cut(train_df['Age'], bins=[9000, 15000, 20000, 25000, 30000], labels=['A', 'B', 'C', 'D'],).astype('category')\ntrain_df['Log_Age'] = np.log1p(train_df['Age'])\nscaler = MinMaxScaler()\ntrain_df['Scaled_Age'] = scaler.fit_transform(train_df['Age'].values.reshape(-1, 1))\ntrain_df = train_df.drop(columns=['id'])\n\ntest_df = pd.read_csv('/kaggle/input/playground-series-s3e26/test.csv')\n\n# Advanced feature engineering for test data\ntest_df['Age_Group'] = pd.cut(test_df['Age'], bins=[9000, 15000, 20000, 25000, 30000], labels=['A', 'B', 'C', 'D']).astype('category')\ntest_df['Log_Age'] = np.log1p(test_df['Age'])\ntest_df['Scaled_Age'] = scaler.transform(test_df['Age'].values.reshape(-1, 1))\n\ntest_df = test_df.drop(columns=['id'])\n\nfts_continuous = list(train_df.select_dtypes(include=['float64', 'int64']).columns)\nfts_categorical = list(train_df.select_dtypes(include=['object','category']).columns)\nfts_categorical.remove('Status')\n\ntrain_df = pd.get_dummies(train_df,\n                       columns=fts_categorical)\ntest_df = pd.get_dummies(test_df, \n                      columns=fts_categorical)\n\nlabel_encoder = LabelEncoder()\ntrain_df['Status'] = label_encoder.fit_transform(train_df['Status'])","metadata":{"_uuid":"974d5816-8023-4f8a-890c-6056204091ae","_cell_guid":"426209ac-1868-4b9f-982f-0f4f02adb9e0","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.241834Z","iopub.execute_input":"2024-02-02T10:55:49.242206Z","iopub.status.idle":"2024-02-02T10:55:49.284102Z","shell.execute_reply.started":"2024-02-02T10:55:49.242176Z","shell.execute_reply":"2024-02-02T10:55:49.282734Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"933670a3-0128-4c67-9f11-f9649eddc1c1","_cell_guid":"2627012d-a90d-4f95-92b8-197a582c69b2","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.285979Z","iopub.execute_input":"2024-02-02T10:55:49.286729Z","iopub.status.idle":"2024-02-02T10:55:49.317408Z","shell.execute_reply.started":"2024-02-02T10:55:49.286687Z","shell.execute_reply":"2024-02-02T10:55:49.316251Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"_uuid":"bbef71bc-af2c-4574-85d1-e442ddec5ed8","_cell_guid":"4ceb2333-64d1-41b9-83c0-cbd0f4279938","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.318605Z","iopub.execute_input":"2024-02-02T10:55:49.319444Z","iopub.status.idle":"2024-02-02T10:55:49.335707Z","shell.execute_reply.started":"2024-02-02T10:55:49.319412Z","shell.execute_reply":"2024-02-02T10:55:49.334411Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the coming AG feature engineering before the engine starts!","metadata":{"_uuid":"b74d7e40-5da8-49e7-b451-4bedc5987919","_cell_guid":"9bde6e36-12bd-4876-b225-77b0b0064abd","trusted":true}},{"cell_type":"code","source":"from autogluon.features.generators import AutoMLPipelineFeatureGenerator\nauto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\nauto_ml_pipeline_feature_generator.fit_transform(X=train_df.drop('Status',axis=1))","metadata":{"_uuid":"a5c31632-29ce-4da7-9db9-4d63598b5396","_cell_guid":"36960150-81f8-42e6-86e6-b3aabd16adb8","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.337292Z","iopub.execute_input":"2024-02-02T10:55:49.338393Z","iopub.status.idle":"2024-02-02T10:55:49.486447Z","shell.execute_reply.started":"2024-02-02T10:55:49.338348Z","shell.execute_reply":"2024-02-02T10:55:49.485048Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### There are many training options in AG, I should recommend using presets='best_quality' in the fit state which in v.1.0.0 has Zero-Shot HPO included and many other SOTA parts. \n### Below we are instead custom tuning the models by first get the deafault parameters from get_hyperparameter_config and also add some of the more advanced architectures to show what other models are included in autogluon tabular like FTTransformer and TabPFN.","metadata":{"_uuid":"db53b5f7-3fa3-49c0-bc34-4e09b13fad3c","_cell_guid":"f4c20857-83cf-4d75-aa4c-bb5b76748579","trusted":true}},{"cell_type":"code","source":"from autogluon.tabular.configs.hyperparameter_configs import get_hyperparameter_config\ncustom_hyperparameters = get_hyperparameter_config('default')\nprint(custom_hyperparameters.keys())\ncustom_hyperparameters['XGB']","metadata":{"_uuid":"1e1b6ccd-4b62-4c56-8ad3-4e3d1d22385c","_cell_guid":"378e6b95-396c-474b-95e3-c601da15664c","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.487824Z","iopub.execute_input":"2024-02-02T10:55:49.488307Z","iopub.status.idle":"2024-02-02T10:55:49.49854Z","shell.execute_reply.started":"2024-02-02T10:55:49.488263Z","shell.execute_reply":"2024-02-02T10:55:49.497132Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### We can also use unlabeled data for the TabTransformer training, which is the only model in AG that uses that option and the model also needs to be added to the training below. It also shows how to add custom search space during training if the hyperparameter_tune_kwargs is used.\n### As we are uing CPU here, we skip this training for now, better using transformers with GPU.","metadata":{"_uuid":"263a01d2-41cf-455b-8473-6eed67534529","_cell_guid":"752a3207-da06-4344-9551-e8837f72ca4e","trusted":true}},{"cell_type":"code","source":"# from autogluon.common import space\n# custom_hyperparameters['TRANSF'] = {\n#         \"lr\": space.Real(5e-5, 5e-3, default=1e-3, log=True),\n#         \"weight_decay\": space.Real(1e-6, 5e-2, default=1e-6, log=True),\n#         \"p_dropout\": space.Categorical(0.1, 0, 0.5),\n#         \"n_heads\": space.Categorical(8, 4),\n#         \"hidden_dim\": space.Categorical(128, 32, 64, 256),\n#         \"n_layers\": space.Categorical(2, 1, 3, 4, 5),\n#         \"feature_dim\": space.Int(8, 128, default=64),\n#         \"num_output_layers\": space.Categorical(1, 2),\n#     }\n# custom_hyperparameters['TABPFN'] = {\"N_ensemble_configurations\": space.Categorical(2, 4, 8)}\n# custom_hyperparameters['FT_TRANSFORMER'] = {}","metadata":{"_uuid":"0077c1f3-e24e-4a73-8c95-b4fcf04aaa88","_cell_guid":"9eca8abe-39cf-4639-b4a3-c3a7cd584efb","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.500399Z","iopub.execute_input":"2024-02-02T10:55:49.50102Z","iopub.status.idle":"2024-02-02T10:55:49.512159Z","shell.execute_reply.started":"2024-02-02T10:55:49.500965Z","shell.execute_reply":"2024-02-02T10:55:49.510759Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's start the training!\n### I leave some options unused so you can try other settings.\n### Time limit is set for the training of the different solutions and also the extra option for HPO tuning within that time limit.\n### We are exluding some deafult models to save some tuning and training time. For the same reason we decrease the folds from deafult 8 to 6.","metadata":{"_uuid":"ba7b4190-b269-401a-8645-dfadae98870a","_cell_guid":"5d274428-d07f-4621-8bdc-e98ae0ea7594","trusted":true}},{"cell_type":"markdown","source":"### Dynamic_stacking option can also be used, the function described below. This take some extra time and we will set it here to Off/False.\n### \"Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n### Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\"\n### 2 stacking level training is AG default with highest option of training.","metadata":{"_uuid":"a05ae23b-88bd-4612-8741-73d7fbf14a50","_cell_guid":"50d237a8-dd32-41c6-b208-bf108e91e7d1","trusted":true}},{"cell_type":"markdown","source":"### There many options one can experiment with like exclude some models and skip the auto feature engineering, I add them but not used, only as example of options. We use the keep_only_best option which removes models after training that not is used in the final ensemble.","metadata":{"_uuid":"c04a57ba-a904-43a1-aefd-212839ef74bd","_cell_guid":"4b52b316-1212-474b-8026-9a2076c81859","trusted":true}},{"cell_type":"code","source":"label = 'Status'\neval_metric = 'log_loss'\npredictor = TabularPredictor(label = label,\n                             sample_weight='auto_weight',\n                             eval_metric = eval_metric,\n                             verbosity = 3).fit(train_df,unlabeled_data=test_df,time_limit=60*60*1,\n                                                presets='best_quality',dynamic_stacking=False,\n                                                ag_args_ensemble = {'fold_fitting_strategy':'sequential_local'},\n                                              #  excluded_model_types=['KNN','XT','RF'],\n                                              #  feature_generator=None,\n                                                num_bag_folds=6,\n                                                hyperparameters = custom_hyperparameters,\n                                                hyperparameter_tune_kwargs='auto',\n                                                num_gpus=0,num_cpus=4,\n                                                keep_only_best=True)","metadata":{"_uuid":"5ff76006-bd15-4ece-967f-fd917a08e88b","_cell_guid":"12f28219-af8f-4930-9d91-33b9edd3c344","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.562679Z","iopub.execute_input":"2024-02-02T10:55:49.563046Z","iopub.status.idle":"2024-02-02T10:55:49.571483Z","shell.execute_reply.started":"2024-02-02T10:55:49.56301Z","shell.execute_reply":"2024-02-02T10:55:49.570318Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we try re-train on a pseudolabel of the test data and see if it improve the score, otherwise it will back and pick the original trained model.","metadata":{"_uuid":"0bfa794a-8ae1-4473-93f2-f5918ce420f3","_cell_guid":"1cac6015-1c22-4d90-b634-d3693c8d8472","trusted":true}},{"cell_type":"code","source":"predictor.fit_pseudolabel(pseudo_data=test_df,use_ensemble=True,return_pred_prob=True,\n                          fit_ensemble=True,it_ensemble_every_iter=True,keep_only_best=True,max_iter=10,\n                            presets='best_quality',dynamic_stacking=True,time_limit=60*60*1,\n                            ag_args_ensemble = {'fold_fitting_strategy':'sequential_local'},\n                           # excluded_model_types=['KNN','XT','RF','TABPFN','GBM','NN_TORCH'],\n                            hyperparameters = custom_hyperparameters,\n                            num_gpus=0,num_cpus=4)","metadata":{"_uuid":"ae5ff29e-6df6-4d2a-bce1-fc6f103c4ed8","_cell_guid":"f7b92f85-22c4-4c8b-a9ab-90a393ab9fa6","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.573451Z","iopub.execute_input":"2024-02-02T10:55:49.573991Z","iopub.status.idle":"2024-02-02T10:55:49.5814Z","shell.execute_reply.started":"2024-02-02T10:55:49.573948Z","shell.execute_reply":"2024-02-02T10:55:49.580174Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor.leaderboard()","metadata":{"_uuid":"523ec488-56a9-4d56-af98-693f1b3229f4","_cell_guid":"3afd412c-f89f-4afe-8e64-9390793a4a29","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we try distillation \n### As described on the AG site:\n### \"Distill AutoGluon’s most accurate ensemble-predictor into single models which are simpler/faster and require less memory/compute. Distillation can produce a model that is more accurate than the same model fit directly on the original training data.\"\n### We also try to use the test set for the extra augmentation data.","metadata":{"_uuid":"f8370800-33d9-4916-b874-4792c2180706","_cell_guid":"07e7e82c-27e8-4c93-9407-137c7e8ddf64","trusted":true}},{"cell_type":"code","source":"## first saving the best trained models for later used.\npredictor_best_model = predictor.leaderboard()['model'][1]\npredictor_best_ensemble = predictor.leaderboard()['model'][0]","metadata":{"_uuid":"46d84ad2-f046-4102-b5d7-a36663f36502","_cell_guid":"c12b8816-aa55-41f8-a65d-53ba90aff81b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor.distill(\n                hyperparameters = {'RF':{},'CAT':{}},#'GBM':{},'NN_TORCH':{},'RF':{},'CAT':{}\n                augment_args = {'size_factor':5, 'max_size': int(1e4)})","metadata":{"_uuid":"67a350a6-042a-4371-ac44-a882ad79b037","_cell_guid":"ac93d9c2-0e0d-4f9c-a4c7-f8341eb711af","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:55:49.583124Z","iopub.execute_input":"2024-02-02T10:55:49.583561Z","iopub.status.idle":"2024-02-02T10:55:49.599527Z","shell.execute_reply.started":"2024-02-02T10:55:49.583516Z","shell.execute_reply":"2024-02-02T10:55:49.598441Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor.leaderboard()","metadata":{"_uuid":"04eed63f-2728-44a5-a31f-8efb7014b013","_cell_guid":"b331055e-5cc6-4fb2-a983-9c641e58e734","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:56:02.757341Z","iopub.execute_input":"2024-02-02T10:56:02.758149Z","iopub.status.idle":"2024-02-02T10:56:02.789808Z","shell.execute_reply.started":"2024-02-02T10:56:02.758106Z","shell.execute_reply":"2024-02-02T10:56:02.788496Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting the pre trained distill model ensemble as primary model and also load it into memory for faster handling \"persist mode\".","metadata":{"_uuid":"2e23c4b1-59c0-47d0-8807-6b41fba3ef7e","_cell_guid":"bede4dd2-6b6a-4fe6-a6f0-c7a9f7e55f45","trusted":true}},{"cell_type":"code","source":"#model_to_deploy = distillmodel.leaderboard()['model'][1]\npredictor.set_model_best('WeightedEnsemble_L2_DSTL')\npredictor.model_best\npredictor.persist()","metadata":{"_uuid":"0f2dfabc-1eed-427e-baf9-43d9ad67240e","_cell_guid":"b31aa069-fc3a-4be1-a4e2-bfdaf53a8449","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T13:09:35.134868Z","iopub.execute_input":"2024-02-02T13:09:35.135374Z","iopub.status.idle":"2024-02-02T13:09:35.158703Z","shell.execute_reply.started":"2024-02-02T13:09:35.135335Z","shell.execute_reply":"2024-02-02T13:09:35.157212Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now let us do an extra training with only some few SOTA models, showing how one can use AutoGluon also as a fast HPO tuning engine. Below will also show how to pick a single Zero-Shot HPO model from the framework. lets start with that and pick the catboost ZS-HPO.","metadata":{"_uuid":"59e0cc17-6884-4b8a-8a7b-3ee5c0338af0","_cell_guid":"e36d56fc-39e7-4238-a660-c64af5621aff","trusted":true}},{"cell_type":"code","source":"from autogluon.tabular.configs.hyperparameter_configs import get_hyperparameter_config\ncustom_hyperparameters = get_hyperparameter_config('zeroshot')\nprint(custom_hyperparameters.keys())","metadata":{"_uuid":"65afe991-85d2-440e-8b90-156f26ddb9be","_cell_guid":"88e3c701-3417-4d55-9e44-c1ab50c5b5f1","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:56:09.225134Z","iopub.execute_input":"2024-02-02T10:56:09.225982Z","iopub.status.idle":"2024-02-02T10:56:09.244167Z","shell.execute_reply.started":"2024-02-02T10:56:09.225947Z","shell.execute_reply":"2024-02-02T10:56:09.242921Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We turn off the dynamic_stacking and stacking levels saving some time. Setthe time limit based on your","metadata":{"_uuid":"97cd276a-87d5-4a40-a33f-6960ac0b5ced","_cell_guid":"e767d8de-1d0b-408e-875a-aabaed6a0e52","trusted":true}},{"cell_type":"code","source":"label = 'Status'\neval_metric = 'log_loss'\npredictor2 = TabularPredictor(label = label,\n                             eval_metric = eval_metric,\n                             verbosity = 3).fit(train_df,\n                                                presets='best_quality',\n                                                dynamic_stacking=False,\n                                                num_stack_levels=0,\n                                                num_bag_folds=6,\n                                                hyperparameters = {'CAT':custom_hyperparameters['CAT']},\n                                                time_limit=60*60*1,\n                                                num_gpus=0,num_cpus=4,\n                                                keep_only_best=True)","metadata":{"_uuid":"2ca32863-81cb-4e59-a4d7-69f4edd17f8f","_cell_guid":"07d5079c-28d4-47cc-b43e-f6e9a6c914d8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor2.leaderboard()","metadata":{"_uuid":"6f2523e2-fa0d-442c-9181-c9ed3544ef68","_cell_guid":"949c9472-ed0c-46db-b937-8b7858404741","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T11:06:31.946709Z","iopub.execute_input":"2024-02-02T11:06:31.948034Z","iopub.status.idle":"2024-02-02T11:06:31.974707Z","shell.execute_reply.started":"2024-02-02T11:06:31.947996Z","shell.execute_reply":"2024-02-02T11:06:31.973765Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we will train an another solution, custom tune selected models parameters on the dataset, we select the three SOTA architectures for it.","metadata":{"_uuid":"a61fa1b9-2f5e-4ad8-a4e0-84f42610d9ac","_cell_guid":"7463de5c-8bad-4a1b-83a6-43aad9e430c1","execution":{"iopub.status.busy":"2024-02-02T10:56:09.984852Z","iopub.status.idle":"2024-02-02T10:56:09.985275Z","shell.execute_reply.started":"2024-02-02T10:56:09.98507Z","shell.execute_reply":"2024-02-02T10:56:09.985088Z"},"trusted":true}},{"cell_type":"code","source":"label = 'Status'\neval_metric = 'log_loss'\npredictor3 = TabularPredictor(label = label,\n                             eval_metric = eval_metric,\n                             verbosity = 3).fit(train_df,\n                                                presets='best_quality',\n                                                dynamic_stacking=False,\n                                                hyperparameter_tune_kwargs='auto',\n                                                time_limit=60*60*1,\n                                                num_bag_folds=6,\n                                                hyperparameters = {'CAT':{},'XGB':{},'GBM':{}},\n                                                num_gpus=0,num_cpus=4,\n                                                keep_only_best=True)","metadata":{"_uuid":"81b85214-685e-4076-a7fd-ac94381cb65b","_cell_guid":"3a7a6fe7-4704-40cb-915a-76d288446f7f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor3.leaderboard()","metadata":{"_uuid":"d767c413-3b3e-40de-85bd-a1db6d37a55d","_cell_guid":"91802f1a-71fc-4256-a8fc-d70ea0f330cd","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T11:14:31.438332Z","iopub.execute_input":"2024-02-02T11:14:31.438816Z","iopub.status.idle":"2024-02-02T11:14:31.465335Z","shell.execute_reply.started":"2024-02-02T11:14:31.438785Z","shell.execute_reply":"2024-02-02T11:14:31.464145Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now to the extra stacking part. This you often see in top solutions in many benchmarks. AG does in the background but here we also do it in custom own created stacking.\n### We take the prediction and training out-of-folder prediction and add that to the orginal dataset as extra features.\n### For this we use four models, the best model from each ensemble, this can reduce the change of overfit instead of using the ensembles. Please try use the ensemble as well, experimenting and study the result is the way.","metadata":{"_uuid":"ebde354e-d4e2-4f62-b23a-227fff50db34","_cell_guid":"42cd6743-8215-4a70-b4cd-289ccacbe3af","trusted":true}},{"cell_type":"markdown","source":"### As distill training doesn't have OOF, it uses that for augmentation, we will not use it for stacking but instead for later ensemble.","metadata":{"_uuid":"8b6ccd1e-2b32-44eb-aca2-786a7ae3fbcd","_cell_guid":"ffdb35f6-89e5-41a5-9933-640bbbf0a1cb","trusted":true}},{"cell_type":"code","source":"## first predict using the distillation model.\nbmodel = predictor.model_best\nprint(bmodel)\npred_distill = predictor.predict_proba(model=bmodel,data=test_df,as_pandas=False)\npred_distill","metadata":{"_uuid":"7c813069-312e-4491-a3dc-e13b5946526c","_cell_guid":"2c824e8c-299f-42f4-9960-c408cb3c8d65","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T13:09:44.169263Z","iopub.execute_input":"2024-02-02T13:09:44.169693Z","iopub.status.idle":"2024-02-02T13:09:44.469112Z","shell.execute_reply.started":"2024-02-02T13:09:44.169649Z","shell.execute_reply":"2024-02-02T13:09:44.467793Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_stacking = train_df.copy()\ntest_df_stacking = test_df.copy()","metadata":{"_uuid":"70c06ac1-e818-441e-96f0-af6fd6056f9e","_cell_guid":"678faa7c-de0c-43ad-bdc1-9b09d1185403","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T11:47:25.7049Z","iopub.execute_input":"2024-02-02T11:47:25.705495Z","iopub.status.idle":"2024-02-02T11:47:25.715532Z","shell.execute_reply.started":"2024-02-02T11:47:25.705449Z","shell.execute_reply":"2024-02-02T11:47:25.714127Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pick the top 5 features from training to the new dataset. Here you can try all feature or some, this is for demo example for what you can do.","metadata":{"_uuid":"874f946e-a906-4e53-b697-788806a32f0a","_cell_guid":"63ee4156-67d3-4915-9c39-b200a34e1bca","trusted":true}},{"cell_type":"code","source":"feature_importance = predictor3.feature_importance(train_df)","metadata":{"_uuid":"c7f46fe4-15f2-410f-b916-e684c8663f22","_cell_guid":"afee481c-7b20-4634-8394-22d1ab21fbb1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coltouse = list(feature_importance[:5].T.columns)\ntrain_df_stacking = train_df_stacking[coltouse+[label]]\ntest_df_stacking = test_df_stacking[coltouse]","metadata":{"_uuid":"514229c1-5940-4518-b021-6dd8f5bc16fc","_cell_guid":"3a438307-42ea-4d6c-a994-1d9cc661d681","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T11:49:52.657474Z","iopub.execute_input":"2024-02-02T11:49:52.657944Z","iopub.status.idle":"2024-02-02T11:49:52.668252Z","shell.execute_reply.started":"2024-02-02T11:49:52.657908Z","shell.execute_reply":"2024-02-02T11:49:52.667049Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Take the best model from the different trained AG solutions and create the new features from test set prediction and train set OOF prediction.","metadata":{"_uuid":"0daa9a47-8bb5-4ba8-8923-fb0826b26552","_cell_guid":"142977b8-a9a8-4535-80a9-9cdb85139129","trusted":true}},{"cell_type":"code","source":"#model_to_deploy = predictor.leaderboard()['model'][1]\npredictor.set_model_best(predictor_best_model)\nbmodel = predictor.model_best\nprint(bmodel)\ntrain_df_stacking[['ag_1_Status_C','ag_1_Status_CL','ag_1_Status_D']] = predictor.get_oof_pred_proba().values\ntest_df_stacking[['ag_1_Status_C','ag_1_Status_CL','ag_1_Status_D']] = predictor.predict_proba(model=bmodel,data=test_df,as_pandas=False)","metadata":{"_uuid":"98ac204b-c347-4ac6-a807-d238fd0e2da7","_cell_guid":"60a31883-06a8-4ed2-ac30-ed6052a1036a","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T11:50:07.81875Z","iopub.execute_input":"2024-02-02T11:50:07.819172Z","iopub.status.idle":"2024-02-02T11:50:12.246053Z","shell.execute_reply.started":"2024-02-02T11:50:07.819141Z","shell.execute_reply":"2024-02-02T11:50:12.244222Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_to_deploy = predictor2.leaderboard()['model'][1]\npredictor2.set_model_best(model_to_deploy)\nbmodel = predictor2.model_best\nprint(bmodel)\ntrain_df_stacking[['ag_2_Status_C','ag_2_Status_CL','ag_2_Status_D']] = predictor2.get_oof_pred_proba().values\ntest_df_stacking[['ag_2_Status_C','ag_2_Status_CL','ag_2_Status_D']] = predictor2.predict_proba(model=bmodel,data=test_df,as_pandas=False)","metadata":{"_uuid":"7ca0c54b-ba0b-42ad-9379-30045ec45ced","_cell_guid":"edda8fde-5ab4-4f95-ac1f-3331f2f61b31","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T11:50:37.901281Z","iopub.execute_input":"2024-02-02T11:50:37.901774Z","iopub.status.idle":"2024-02-02T11:50:38.284142Z","shell.execute_reply.started":"2024-02-02T11:50:37.901738Z","shell.execute_reply":"2024-02-02T11:50:38.283004Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_to_deploy = predictor3.leaderboard()['model'][1]\npredictor3.set_model_best(model_to_deploy)\nbmodel = predictor3.model_best\nprint(bmodel)\ntrain_df_stacking[['ag_3_Status_C','ag_3_Status_CL','ag_3_Status_D']] = predictor3.get_oof_pred_proba().values\ntest_df_stacking[['ag_3_Status_C','ag_3_Status_CL','ag_3_Status_D']] = predictor3.predict_proba(model=bmodel,data=test_df,as_pandas=False)","metadata":{"_uuid":"2c450b64-0eb9-4f62-8aa6-ff568ca5774e","_cell_guid":"fbafaebd-def4-415c-8e2f-97180254619d","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T11:51:14.24305Z","iopub.execute_input":"2024-02-02T11:51:14.243507Z","iopub.status.idle":"2024-02-02T11:51:14.405307Z","shell.execute_reply.started":"2024-02-02T11:51:14.243473Z","shell.execute_reply":"2024-02-02T11:51:14.403958Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_stacking","metadata":{"_uuid":"3a7d82f1-881e-48eb-8906-acb83ff29c0d","_cell_guid":"481e28c9-b7d0-4b24-a0cb-d1ab51ef58f9","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T12:26:14.717262Z","iopub.execute_input":"2024-02-02T12:26:14.717782Z","iopub.status.idle":"2024-02-02T12:26:14.752114Z","shell.execute_reply.started":"2024-02-02T12:26:14.717742Z","shell.execute_reply":"2024-02-02T12:26:14.751131Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"17ccc610-6897-4362-b904-e7de74f57cf3","_cell_guid":"cee02696-b3e5-40ca-9c03-2f2d876ff45d","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T12:47:33.906404Z","iopub.execute_input":"2024-02-02T12:47:33.91005Z","iopub.status.idle":"2024-02-02T12:47:33.958067Z","shell.execute_reply.started":"2024-02-02T12:47:33.909989Z","shell.execute_reply":"2024-02-02T12:47:33.956814Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we will train a final stacked solution with a tuned XGB as meta model.","metadata":{"_uuid":"77d005b4-04c2-4110-a014-26085e67ec1c","_cell_guid":"a22f1fe4-4cd4-4cac-8567-8bfafd4fc8ac","trusted":true}},{"cell_type":"code","source":"custom_hyperparameters = get_hyperparameter_config('default')\ncustom_hyperparameters['TABPFN'] = {}\nlabel = 'Status'\neval_metric = 'log_loss'\npredictor_final = TabularPredictor(label = label,\n                             eval_metric = eval_metric,\n                             verbosity = 3).fit(train_df_stacking,\n                                                presets='best_quality',\n                                                dynamic_stacking=False,\n                                                num_stack_levels=0,\n                                                hyperparameter_tune_kwargs='auto',\n                                                hyperparameters = {'XGB':custom_hyperparameters['XGB']},\n                                                time_limit=60*60*1,\n                                                num_bag_folds=6,\n                                                num_gpus=0,num_cpus=4,\n                                                keep_only_best=True)","metadata":{"_uuid":"a605c1a1-907d-48d8-96b8-3a05f448070b","_cell_guid":"50950973-fc74-4caa-9925-96530b3ce96c","collapsed":false,"execution":{"iopub.status.idle":"2024-02-02T13:08:14.011704Z","shell.execute_reply.started":"2024-02-02T12:59:32.157508Z","shell.execute_reply":"2024-02-02T13:08:14.010203Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor_final.leaderboard()","metadata":{"_uuid":"8f8c49cb-1333-430f-a920-f0c3f8445cda","_cell_guid":"07cf39dc-ae46-4780-bb24-065ed23c5da5","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T13:09:06.920706Z","iopub.execute_input":"2024-02-02T13:09:06.922419Z","iopub.status.idle":"2024-02-02T13:09:06.95644Z","shell.execute_reply.started":"2024-02-02T13:09:06.92236Z","shell.execute_reply":"2024-02-02T13:09:06.955089Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred = predictor_final.predict_proba(test_df_stacking)\nfinal_pred","metadata":{"_uuid":"3613bc64-5daf-46f4-a487-033676636bb5","_cell_guid":"043e9857-511f-4cac-be73-d58a6f1696e2","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T13:09:12.425066Z","iopub.execute_input":"2024-02-02T13:09:12.425509Z","iopub.status.idle":"2024-02-02T13:09:13.39908Z","shell.execute_reply.started":"2024-02-02T13:09:12.425475Z","shell.execute_reply":"2024-02-02T13:09:13.397882Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/playground-series-s3e26/sample_submission.csv\")","metadata":{"_uuid":"76df7789-d30f-46be-ab9b-d9d7c9a2b94a","_cell_guid":"1bf72dd5-1c26-437f-b959-f8db56350e51","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T12:44:01.221265Z","iopub.execute_input":"2024-02-02T12:44:01.222406Z","iopub.status.idle":"2024-02-02T12:44:01.248621Z","shell.execute_reply.started":"2024-02-02T12:44:01.222361Z","shell.execute_reply":"2024-02-02T12:44:01.247344Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finally we ensemle with all the AG solutions trained in this notebook.","metadata":{"_uuid":"d967d84f-75dd-424d-8df4-cb8fd9caf827","_cell_guid":"d9f33a21-f4cf-40f8-8956-70f9a7391114","trusted":true}},{"cell_type":"code","source":"## First predict using the best ensembles for every solution.\npredictor.set_model_best(predictor_best_ensemble)\nbmodel = predictor.model_best\nprint(bmodel)\npred1 = predictor.predict_proba(model=bmodel,data=test_df)\n\nmodel_to_deploy = predictor2.leaderboard()['model'][0]\npredictor2.set_model_best(model_to_deploy)\nbmodel = predictor2.model_best\nprint(bmodel)\npred2 = predictor2.predict_proba(model=bmodel,data=test_df)\n\nmodel_to_deploy = predictor3.leaderboard()['model'][0]\npredictor3.set_model_best(model_to_deploy)\nbmodel = predictor3.model_best\nprint(bmodel)\npred3 = predictor3.predict_proba(model=bmodel,data=test_df)","metadata":{"_uuid":"7d51235a-e8df-4983-aed8-89879dd25136","_cell_guid":"3b2d2e78-fa86-4dda-ada3-de162b313832","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## remove all the trained models, as we only need the predictions for now.\n!rm -r *","metadata":{"_uuid":"5cb42ba3-c3b9-4552-9c39-c34d2204d3e5","_cell_guid":"bce37615-8667-4f02-941e-dbd10f80758a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Ensemble all the predictions.\nsub.iloc[:,1:] = (final_pred.values*.6 +  pred_distill*.4)*.5 + pred1.values*.2 + pred2.values*.2 + pred3.values*.1\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"_uuid":"082adfa2-15d5-4202-9940-bed8d994cc26","_cell_guid":"b54fdab3-0793-4f32-a908-13b5a6491878","collapsed":false,"execution":{"iopub.status.busy":"2024-02-02T10:56:10.002136Z","iopub.status.idle":"2024-02-02T10:56:10.002866Z","shell.execute_reply.started":"2024-02-02T10:56:10.002621Z","shell.execute_reply":"2024-02-02T10:56:10.002639Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## That's it!","metadata":{"_uuid":"192978bb-3c99-4514-a251-b753876b096e","_cell_guid":"4f95b877-33f3-4ed1-98e0-9f452cab48e6","trusted":true}}]}